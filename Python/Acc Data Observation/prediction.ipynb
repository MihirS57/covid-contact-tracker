{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1366e315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n",
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%autosave 120\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae2e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Version number (Walk): 1\n"
     ]
    }
   ],
   "source": [
    "dataset_ver_walk = input('Dataset Version number (Walk): ')\n",
    "walk_dataset = pd.read_csv(f'./Sample Datasets/Sample_walk_dataset_{dataset_ver_walk}.csv')\n",
    "#test_walk_dataset = pd.read_csv(f'./Sample Datasets/Test_walk_dataset_{dataset_ver_walk}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51e1cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Version number (Run): 1\n"
     ]
    }
   ],
   "source": [
    "dataset_ver_run = input('Dataset Version number (Run): ')\n",
    "run_dataset = pd.read_csv(f'./Sample Datasets/Sample_run_dataset_{dataset_ver_run}.csv')\n",
    "#test_run_dataset = pd.read_csv(f'./Sample Datasets/Test_run_dataset_{dataset_ver_run}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e018bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spikes(list,TS):\n",
    "    std_spike_val = 8\n",
    "    diff_ts_spike = 1.0\n",
    "    prev_spike_ts = 0.0\n",
    "    counter = 0\n",
    "    for idx,val in enumerate(list):\n",
    "        if val >= std_spike_val and TS[idx] - prev_spike_ts >= diff_ts_spike:\n",
    "            counter+=1\n",
    "            prev_spike_ts = TS[idx]\n",
    "        \n",
    "    print(f'Number of spikes: {counter}')\n",
    "\n",
    "def plot_one_plot():\n",
    "    val = input('Which section? (X,Y,Z,Acc): ')\n",
    "    if val == 'X':\n",
    "        plt.plot(TS,X,color=\"red\",linewidth=1.0)\n",
    "    elif val == 'Y':\n",
    "        plt.plot(TS,Y,color=\"red\",linewidth=1.0)\n",
    "    elif val == 'Z':\n",
    "        plt.plot(TS,Z,color=\"red\",linewidth=1.0)\n",
    "    else:\n",
    "        plt.axhline(y=12.5)\n",
    "        plt.axhline(y=10)\n",
    "        plt.scatter(TS,Acc,s=10,color=\"blue\")\n",
    "        plt.plot(TS,Acc,color=\"red\",linewidth=1.0)\n",
    "    plt.xlabel('Time Stamp')\n",
    "    plt.ylabel('acceleration in m/s (Gravity Incl)')\n",
    "\n",
    "\n",
    "def plot_sub_plots():\n",
    "    figure, axis = plt.subplots(2, 2)\n",
    "\n",
    "    axis[0,0].plot(TS,X,color=\"red\",linewidth=1.0)\n",
    "    axis[0,0].set_title(\"WRT X Values\")\n",
    "\n",
    "    axis[0,1].plot(TS,Y,color=\"blue\",linewidth=1.0)\n",
    "    axis[0,1].set_title(\"WRT Y Values\")\n",
    "\n",
    "    axis[1,0].plot(TS,Z,color=\"yellow\",linewidth=1.0)\n",
    "    axis[1,0].set_title(\"WRT Z Values\")\n",
    "\n",
    "    axis[1,1].plot(TS,X,color=\"red\",linewidth=1.0)\n",
    "    axis[1,1].plot(TS,Y,color=\"blue\",linewidth=1.0)\n",
    "    axis[1,1].plot(TS,Z,color=\"yellow\",linewidth=1.0)\n",
    "    axis[1,1].plot(TS,Acc,color=\"grey\",linewidth=1.0)\n",
    "    axis[1,1].set_title(\"WRT X,Y,Z,ACC Values\")\n",
    "    \n",
    "def preprocessForXandY(dataset_walk, dataset_run):\n",
    "    X_walk = dataset_walk.iloc[:,[1,3,4,5,6,7,8]]\n",
    "    y_walk = dataset_walk.iloc[:,[2]]\n",
    "    X_run = dataset_run.iloc[:,[1,3,4,5,6,7,8]]\n",
    "    y_run = dataset_run.iloc[:,[2]]\n",
    "    \n",
    "    X_frames = [X_walk,X_run]\n",
    "    X = pd.concat(X_frames)\n",
    "    Y_frames = [y_walk,y_run]\n",
    "    y = pd.concat(Y_frames)\n",
    "    return X,y\n",
    "\n",
    "def preprocessAndSplit(dataset_walk, dataset_run):\n",
    "    W_train, W_test, Wy_train, Wy_test = train_test_split(dataset_walk.iloc[:,[1,3,4,5,6,7,8]],\n",
    "                                                      dataset_walk.iloc[:,[2]], test_size=0.25, shuffle=False, stratify=None)\n",
    "    R_train, R_test, Ry_train, Ry_test = train_test_split(dataset_run.iloc[:,[1,3,4,5,6,7,8]],\n",
    "                                                      dataset_run.iloc[:,[2]], test_size=0.25, shuffle=False, stratify=None)\n",
    "    X_train = pd.concat([W_train,R_train])\n",
    "    y_train = pd.concat([Wy_train,Ry_train])\n",
    "    X_test = pd.concat([W_test,R_test])\n",
    "    y_test = pd.concat([Wy_test,Ry_test])\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "def makeOneObservation(input_dataset):\n",
    "    row,col = total_observations = input_dataset.shape\n",
    "    print(row,col)\n",
    "    new_observation = np.array([['TS','Age','Mode',\n",
    "                                'Xa_1','Ya_1','Za_1','Xg_1','Yg_1','Zg_1','Acc1',\n",
    "                                'Xa_2','Ya_2','Za_2','Xg_2','Yg_2','Zg_2','Acc2',\n",
    "                                'Xa_3','Ya_3','Za_3','Xg_3','Yg_3','Zg_3','Acc3',\n",
    "                                'Xa_4','Ya_4','Za_4','Xg_4','Yg_4','Zg_4','Acc4'\n",
    "                                ]])\n",
    "    #print(new_observation)\n",
    "    ts_i = 0\n",
    "    #print(input_dataset.iloc[[ts_i,ts_i+1,ts_i+2,ts_i+3],[1,2,3,4,5,6,7,8]])\n",
    "    for ts_i in range(0,row,4):\n",
    "        a = np.array([[input_dataset.iloc[ts_i,0],\n",
    "                       input_dataset.iloc[ts_i,1],\n",
    "                       input_dataset.iloc[ts_i,2],\n",
    "                       input_dataset.iloc[ts_i,3], input_dataset.iloc[ts_i,4],input_dataset.iloc[ts_i,5],\n",
    "                       input_dataset.iloc[ts_i,6], input_dataset.iloc[ts_i,7],input_dataset.iloc[ts_i,8],\n",
    "                       input_dataset.iloc[ts_i,9],\n",
    "                       input_dataset.iloc[ts_i+1,3], input_dataset.iloc[ts_i+1,4],input_dataset.iloc[ts_i+1,5],\n",
    "                       input_dataset.iloc[ts_i+1,6], input_dataset.iloc[ts_i+1,7],input_dataset.iloc[ts_i+1,8],\n",
    "                       input_dataset.iloc[ts_i+1,9],\n",
    "                       input_dataset.iloc[ts_i+2,3], input_dataset.iloc[ts_i+2,4],input_dataset.iloc[ts_i+2,5],\n",
    "                       input_dataset.iloc[ts_i+2,6], input_dataset.iloc[ts_i+2,7],input_dataset.iloc[ts_i+2,8],\n",
    "                       input_dataset.iloc[ts_i+2,9],\n",
    "                       input_dataset.iloc[ts_i+3,3], input_dataset.iloc[ts_i+3,4],input_dataset.iloc[ts_i+3,5],\n",
    "                       input_dataset.iloc[ts_i+3,6], input_dataset.iloc[ts_i+3,7],input_dataset.iloc[ts_i+3,8],\n",
    "                       input_dataset.iloc[ts_i+3,9]\n",
    "                      ]])\n",
    "        new_observation = np.append(new_observation, a, axis=0)\n",
    "\n",
    "    return new_observation\n",
    "\n",
    "def accuracyNums(y_exp, y_pred):\n",
    "    model_accuracy = accuracy_score(y_exp, y_pred)\n",
    "    return (model_accuracy,confusion_matrix(y_exp,y_pred))\n",
    "\n",
    "def saveMyModel(model,version_num):\n",
    "    file_name = f'trained_models/run_walk_model_v{version_num}'\n",
    "    if os.path.isfile(f'{file_name}.h5') is False:\n",
    "        model.save(f'{file_name}.h5')\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f'{file_name}.tflite', 'wb') as f:\n",
    "      f.write(tflite_model)\n",
    "    interpreter = tf.lite.Interpreter(model_path=f'{file_name}.tflite')\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    print(f'Model saved as: {file_name} in h5 and tflite')\n",
    "    # Print input shape and type\n",
    "    inputs = interpreter.get_input_details()\n",
    "    print('{} input(s):'.format(len(inputs)))\n",
    "    for i in range(0, len(inputs)):\n",
    "        print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))\n",
    "\n",
    "    # Print output shape and type\n",
    "    outputs = interpreter.get_output_details()\n",
    "    print('\\n{} output(s):'.format(len(outputs)))\n",
    "    for i in range(0, len(outputs)):\n",
    "        print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = input('run or walk? ')\n",
    "if choice == 'run':\n",
    "    matrix = run_dataset\n",
    "else:\n",
    "    matrix = walk_dataset\n",
    "plot_type = input('What type of plot? Single (S) or Multiple (M) or count spikes (CS): ')\n",
    "#LR = matrix.iloc[:,[0]].values\n",
    "RW = matrix.iloc[:,[2]].values\n",
    "X = matrix.iloc[:,[3]].values\n",
    "Y = matrix.iloc[:,[4]].values\n",
    "Z = matrix.iloc[:,[5]].values\n",
    "Acc = matrix.iloc[:,[9]].values\n",
    "#TS_i = matrix.iloc[:,[4]].values[0]\n",
    "#TS = (matrix.iloc[:,[4]].values - TS_i)/100000000\n",
    "TS = matrix.iloc[:,[0]].values\n",
    "if TS[0] > 100000000:\n",
    "    TS = convert_ts(TS)\n",
    "if plot_type == 'S':\n",
    "    plot_one_plot()\n",
    "elif plot_type == 'M': \n",
    "    plot_sub_plots()\n",
    "else:\n",
    "    count_spikes(Acc,TS=TS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b61ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = preprocessForXandY(walk_dataset,run_dataset)\n",
    "X_train,y_train,X_test,y_test = preprocessAndSplit(walk_dataset,run_dataset)\n",
    "# X_train,y_train = preprocessForXandY(W_train,R_train)\n",
    "# X_test,y_test = preprocessForXandY()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, shuffle=True, stratify=None)\n",
    "print(f'{X} \\n {y} \\n {X_train} \\n {y_train} \\n {X_test} \\n {y_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40112301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v = input('Version: ')\n",
    "file_name = f'trained_models/run_walk_model_v{model_v}.h5'\n",
    "model = keras.models.load_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18825f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(7,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,y=y_train, batch_size=5, validation_split=0.1,epochs=50, shuffle=False,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ab468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_walk_dataset = pd.read_csv(f'./Sample Datasets/Sample_walk_dataset_2.csv')\n",
    "# new_run_dataset = pd.read_csv(f'./Sample Datasets/Sample_run_dataset_2.csv')\n",
    "# test_X,test_y = preprocessForXandY(new_walk_dataset,new_run_dataset)\n",
    "X_walk = walk_dataset.iloc[:,[1,3,4,5,6,7,8]]\n",
    "y_walk = walk_dataset.iloc[:,[2]]\n",
    "model_predictions = model.predict(x=X_walk, batch_size=10, verbose=0)\n",
    "round_pred = np.argmax(model_predictions, axis=-1)\n",
    "print(accuracyNums(y_walk,round_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac5fd4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 10\n",
      "[['TS' 'Age' 'Mode' 'Xa_1' 'Ya_1' 'Za_1' 'Xg_1' 'Yg_1' 'Zg_1' 'Acc1'\n",
      "  'Xa_2' 'Ya_2' 'Za_2' 'Xg_2' 'Yg_2' 'Zg_2' 'Acc2' 'Xa_3' 'Ya_3' 'Za_3'\n",
      "  'Xg_3' 'Yg_3' 'Zg_3' 'Acc3' 'Xa_4' 'Ya_4' 'Za_4' 'Xg_4' 'Yg_4' 'Zg_4'\n",
      "  'Acc4']]\n",
      "   Age  Mode  X_a  Y_a  Z_a  X_g  Y_g  Z_g\n",
      "0   21     1  0.0  0.1 -0.2  0.0  0.1  0.0\n",
      "1   21     1 -0.1  0.0  0.3  0.0  0.1  0.0\n",
      "2   21     1  0.4  0.1 -0.1  0.0  0.1  0.0\n",
      "3   21     1  0.0  0.1 -0.1  0.0  0.0  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['TS', 'Age', 'Mode', ..., 'Yg_4', 'Zg_4', 'Acc4'],\n",
       "       ['0.0', '21.0', '1.0', ..., '0.0', '0.0', '0.1'],\n",
       "       ['1.7', '21.0', '1.0', ..., '0.0', '0.0', '1.4'],\n",
       "       ...,\n",
       "       ['1016.9', '21.0', '1.0', ..., '-0.1', '-0.2', '2.4'],\n",
       "       ['1018.9', '21.0', '1.0', ..., '-0.2', '-0.1', '0.2'],\n",
       "       ['1020.9', '21.0', '1.0', ..., '0.0', '0.0', '0.2']], dtype='<U32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = makeOneObservation(walk_dataset)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_walk_dataset = pd.read_csv(f'./Sample Datasets/Sample_walk_dataset_3.csv')\n",
    "# new_run_dataset = pd.read_csv(f'./Sample Datasets/Sample_run_dataset_3.csv')\n",
    "# X,y = preprocessForXandY(new_walk_dataset,new_run_dataset)\n",
    "# preds = model.predict(X)\n",
    "# preds\n",
    "# print(model.predict([[-0.5,-0.6,0.5],\n",
    "# [0.5,-1.3,-0.1],\n",
    "# [0,-0.2,-1.3],\n",
    "# [-0.3,-0.2,-0.6],\n",
    "# [0.1,-1.3,1.2]]))\n",
    "\n",
    "\n",
    "# print(model.predict([[0.4,1.4,-6.9],\n",
    "# [-0.9,1.2,-2.2],\n",
    "# [-2.1,1.8,1.9],\n",
    "# [-1.8,3,2.2],\n",
    "# [1.5,3.7,2.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMyModel(model,input('Model Version No. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eababed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12298a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0305a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_walk_dataset = pd.read_csv(f'./Sample Datasets/Sample_walk_dataset_3.csv')\n",
    "new_run_dataset = pd.read_csv(f'./Sample Datasets/Sample_run_dataset_1.csv')\n",
    "test_X,test_y = preprocessForXandY(new_walk_dataset,new_run_dataset)\n",
    "prediction_KNN = KNN.predict(test_X)\n",
    "accuracy_knn = accuracy_score(test_y, prediction_KNN)\n",
    "print (accuracy_knn,confusion_matrix(test_y,prediction_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMyModel(KNN,input('Model Version No. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_KNN = KNN.predict([[0.4,1.4,-6.9],\n",
    "[-0.9,1.2,-2.2],\n",
    "[-2.1,1.8,1.9],\n",
    "[-1.8,3,2.2],\n",
    "[1.5,3.7,2.2]])\n",
    "prediction_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8348d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
